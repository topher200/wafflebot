# Publish Podcast to S3 Service

This service handles publishing the generated podcast audio file to an AWS S3 bucket with ISO 8601 timestamp naming.

## Purpose

The `publish-podcast-to-s3` service takes the generated podcast audio file from the `audio-mixer` service and uploads it to an S3 bucket with a timestamp-based filename.

## How it Works

1. **Input**: Reads the generated podcast file from the `podcast-audio` Docker volume (mounted as read-only)
2. **Processing**: Generates a filename with ISO 8601 timestamp format: `YYYY-MM-DDTHHMMSS.mp3`
3. **Output**: Uploads the file to the S3 bucket using AWS CLI

## Authentication

This service uses AWS access keys for authentication. The credentials should be generated using `aws-vault` on the host machine and then passed to the container via environment variables.

### Setting up credentials with aws-vault

On the host machine, use aws-vault to generate temporary credentials:

```bash
# Generate temporary credentials (valid for 1 hour by default)
aws-vault exec your-profile -- env | grep AWS_ > .env.aws

# Then source these into your .env file
cat .env.aws >> .env
```

## Environment Variables

- `S3_BUCKET_NAME`: The name of the S3 bucket where podcasts will be stored
- `AWS_ACCESS_KEY_ID`: AWS access key (generated by aws-vault)
- `AWS_SECRET_ACCESS_KEY`: AWS secret key (generated by aws-vault)
- `AWS_SESSION_TOKEN`: AWS session token (generated by aws-vault, if using temporary credentials)
- `AWS_REGION`: AWS region (optional, defaults to us-east-1)

## Docker Integration

The service is configured in `docker-compose.yml` as:

```yaml
publish-podcast-to-s3:
  build:
    context: .
  volumes:
    - podcast-audio:/app/data/podcast:ro  # Read-only access to generated audio
    - ./.env:/app/.env:ro                 # Environment variables
  command: bash src/publish-podcast-to-s3/publish.sh
```

## Usage

The service can be run as part of the full pipeline or individually:

```bash
# Generate AWS credentials first
aws-vault exec your-profile -- env | grep AWS_ > .env.aws
cat .env.aws >> .env

# Run as part of the full pipeline
./run-wafflebot.sh

# Or run individually
docker compose run --rm publish-podcast-to-s3
```

## S3 Bucket Structure

Files are uploaded to the S3 bucket with the following structure:

```
s3://your-bucket-name/
└── podcasts/
    ├── 2025-01-15T143022.mp3
    ├── 2025-01-16T091545.mp3
    └── ...
```

## Prerequisites

- AWS CLI installed in the Docker container
- aws-vault configured on the host machine with appropriate AWS credentials
- S3 bucket created (typically via Terraform infrastructure)
- Appropriate IAM permissions for S3 upload operations

## Testing

```bash
# Run all publish tests
uv run pytest src/publish-podcast-to-s3/test_publish.py -v
```
